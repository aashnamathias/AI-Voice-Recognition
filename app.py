# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-q3bABvYx_c-UUyUN-Ep5BHoKysyeDhj
"""

# Commented out IPython magic to ensure Python compatibility.
import streamlit as st
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
from deepmultilingualpunctuation import PunctuationModel
import torch
import torchaudio
import tempfile
import re

st.title("üéôÔ∏è Voice Recognition")

# Helper function to capitalize sentences
def capitalize_sentences(text):
    return re.sub(r'([.?!]\s+)([a-z])', lambda m: m.group(1) + m.group(2).upper(), text).capitalize()

# Load models
@st.cache_resource
def load_model():
    processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-large-960h-lv60-self")
    model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-large-960h-lv60-self")
    return processor, model

@st.cache_resource
def load_punct_model():
    return PunctuationModel()

processor, model = load_model()
punct_model = load_punct_model()

uploaded_file = st.file_uploader("Upload a WAV file", type=["wav"])

if uploaded_file is not None:
    st.audio(uploaded_file)

    # Save the uploaded file to a temporary file
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    # Try to load the audio file with error handling
    try:
        speech_array, sampling_rate = torchaudio.load(tmp_path)
    except Exception as e:
        st.error(f"Error loading audio file: {e}")
        st.stop()

    # Conditional resampling
    if sampling_rate != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)
        speech = resampler(speech_array).squeeze().numpy()
    else:
        speech = speech_array.squeeze().numpy()

    # Process the speech input
    inputs = processor(speech, sampling_rate=16000, return_tensors="pt", padding=True)

    # Transcription
    with st.spinner("Transcribing... please wait ‚è≥"):
        with torch.no_grad():
            logits = model(**inputs).logits
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.decode(predicted_ids[0])

    st.markdown("### ‚úèÔ∏è Raw Transcription:")
    st.success(transcription)
    st.markdown(f"**üî¢ Word Count:** {len(transcription.split())}")

    # Punctuation restoration
    with st.spinner("Restoring punctuation... ‚úçÔ∏è"):
        punctuated_text = punct_model.restore_punctuation(transcription)
        punctuated_text = capitalize_sentences(punctuated_text)

    st.markdown("### üìù Transcription with Punctuation:")
    st.info(punctuated_text)
